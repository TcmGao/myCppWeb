## 基础知识学习
##### 1. 链接  
  * 创建静态链接库  
    ```
    # 1. 创建
    gcc -c addvec.c multvec.c
    # rcs中，r是替换库中旧目标文件；c是创无论静态库是否存在，都创建新静态库，s是为目标文件建立索引，加快链接过程
    ar rcs libvector.a addvec.o multvec.o
    # 2. 使用
    gcc -o prog main.o ./libvector.a 
    # 或者使用-L指定查找目录
    gcc -o prog main.o -L. -lvector
    ```
  * 创建动态链接库
    ```
    # 1.创建
    gcc -shared -fpic -o libvector.so addvec.c multvec.c
    # 2.使用
    gcc -o prog main.c -L. -lvector
    # 或者
    gcc -o prog main.c ./libvector.so

    # fpic即position-independent code，位置无关代码，使得动态库可加载到内存任意位置而无需链接器做修改
    ```
  * PIC(Position-Independent Code)
    * GOT(Global Offset Table)
      GOT即全局偏移量表，利用数据段和代码段相对位置是一个运行时常量的性质。为每一个动态库中的符号(变量或者函数)建立一个8 Bytes的entry，把符号地址填入每一个entry，这样运行时通过一次间接引用，就可以知道符号的运行时地址。
      GOT在动态库内部会使用，因为数据段和代码段相对位置是确定的，这样在制作so时就能生成位置无关代码，动态库内部的重定位条目就可以被确定下来而不是在链接时才能确定，这样的代价自然就是多了一次间接引用，效率受到影响。
    * PLT(Procedure Linkage Table)
      光是GOT还不够，目标模块在调用动态库时，还不知道要调用的函数在哪，此时为了实现PIC，就需要在运行时借助PLT确定GOT条目。(也可以在加载共享库时解析重定位条目，但这不是PIC，因为需要链接器修改调用模块的代码段，这其实就和静态库没有区别了，需要在链接时就加载所有的库函数，确定重定位条目)。
      真正的动态库就是使用延迟绑定，利用PLT的辅助，在运行时加载需要的函数。一个PLT条目时16 Bytes，原理如下：
      1. 调用模块会跳转到自己的PLT中对应的条目。这个条目包含了一段代码，例如：jump GOT[4]，即跳转到GOT条目对应的地址中。
      2. GOT条目初始时包含的是PLT下一条指令的地址，所以只是简单把控制传送回PLT的下一条指令。
      3. 第二条PLT指令会把GOT条目的id，也就是在GOT中的条目偏移压入栈，例如: pushq $0x1，第[4条]GOT条目的偏移就是[1]，因为前3条GOT条目是特殊值。
      4. 下一条指令跳转到PLT第[0]个条目，先把动态库id压入栈，再jump 到动态链接器。
      5. 动态链接器通过压入的GOT条目偏移，通过一个编译过程中生成的映射关系，找到要调用的实际函数id，这个id再去对应动态库中的函数，找到这个函数地址后，调用函数，把函数地址写入GOT条目。
      6. 下一次再调用函数时，只需要一次间接跳转就可以了

##### 2. 字符集和编码
  * unicode字符集是一种字符集，为每一个字符都分配了一个唯一的id。
  * utf-8是一种编码方案，用于存储和传输字符序列，兼容ascii字符集。显然，编码方案就是为了让字符集的多个id组成序列时，可以被识别(简单来说就是知道每个字符应该读多少长度，拼接出一个Unicode字符)。Java的char就是unicode的基本多文种平面，也就是一个码点。

##### 3.网络相关
1. 为什么需要TCP
  * 答：
    1. ip层是不可靠的,ip层不保证包的包交付，也不保证包按序交付，还不保证包的正确性：只校验头部信息。
    2. tcp是基于连接的(1对1)、可靠的、字节流传输协议(无边界，可以接受任意大小的消息)，能够保证数据正确性、有序性(按序、非冗余、无间隔)。
    3. 实际上：连接的定义就是一些信息的组合，这些信息用于保证可靠性和流量控制等，包括了：四元组(ip:port,ip:port)，序列号和窗口大小。所以，一个tcp连接建立需要确认三个信息：四元组(寻址)、序列号(顺序)、窗口大小(流量控制)
2. udp和tcp的区别
  * 答: 
    1. udp无连接，支持一对多、对多对，一对一、而tcp只支持一对一
    2. udp不可靠
    3. udp不关心网络状况，包括拥塞和流量控制
3. 三次握手过程
  * 答: 
    1. 服务端处于监听状态，客户端处于close状态
    2. 客户端随机初始化一个seq，SYN置为1，不包含应用数据，并发送给服务端，进入syn_sent
    3. 服务端接收到syn报文，随机初始化seq，ack设为客户端seq+1，ACK设为1，不包含应用数据，发送给客户端，进入syn_rcvd
    4. 客户端接收到ack之后，进入established。ACK=1，ack=服务端seq+1，服务端接收到数据后进入eatablished。
    **注意**：第三个报文可以包含应用数据，即使不包含应用数据，也会消耗一个序列号。同时，第三个报文没有来自服务端的ack报文，如果服务端没有正确收到这个报文，会触发超时重传，这时客户端会重发报文。
    **注意**：虽然理论上第三个握手报文可以传递数据，但是实际中一般不会这样做，而是严格遵守三次握手流程。
4. 为什么是三次握手
  * 答: 
    1. 三次握手才可以保证双方具有接受和发送能力，两次握手不能保 证客户端能正常接受消息，四次握手没有必要。
    2. 三次才可以初始化socket、序列号、窗口大小，以建立连接
        * **三次握手阻止重复连接初始化**：如果因为网络原因，第一个SYN报文超时，并且早于新的SYN报文抵达，那么服务端会先ack旧报文，此时客户端发现ack不是自己想要的，于是发送rst报文中止这个旧连接，等待新SYN的ack信息。如果是两次握手，则服务端无法判断这多个连接哪一个才是有效的，于是建立多个连接，此时是完全错误的，因为这多个连接的ip:port是一样的。而三次握手就可以先进入sync_rcvd状态，如果收到旧的sync，由于ip:port一致，但是seq_num小，并不重要，直接ack，客户端发现问题后会主动rst
        * **双方同步序列号**: 这是非常重要的，因为序列号才能构建出对应的窗口。而两次握手不能保证客户端接收到了服务端的序列号

5. 四次挥手
  * 答：
    1. 客户端发送FIN，进入FIN_WAIT1
    2. 服务端返回ACK，进入CLOSE_WAIT
    3. 客户端收到ACK，进入FIN_WAIT2
    4. 服务端发送FIN，进入LAST_ACK
    5. 客户端收到FIN，发送ACK，进入TIME_WAIT
    6. 服务端收到ACK，CLOSE
    7. 客户端经过TIME_WAIT，进入CLOSE
  * TIME_WAIT是为了保证服务端能正常关闭，如果没有time_wait，一旦ack丢失，则服务端处于last_ack，不会关闭连接，只有多次重发失败后，服务端才会断开连接。2MSL是为了保证当前连接的数据包在网络中正常消亡，以至于下一次连接不会接收到旧的数据包
6. 流量控制
  * 答：
    1. 流量控制是端对端的，主要是接收方告知发送方，控制发送速率，避免超过处理能力。而如果接收方告知发送方，自己的接受窗口为0时，发送方不允许再发送数据，但是会每隔一段时间发送探测报文。
    2. Nagle算法：提高网络吞吐，当应用层按字节提交数据时，先发送一个字节，缓存后续到达的字节，接受到ack后，再发送剩下字节。在等待期间，缓存应用层提交的数据，直到下一个ack到达，这能有效提高网络吞吐。
7. 拥塞控制
  * 答：拥塞控制是一个全局问题，是为了解决网络发生拥堵的，和流量控制不同
    1. 维护拥塞窗口，发送窗口需要保持和拥塞窗口同步
    2. 慢启动：开始窗口设置为1，每接收到一个ack，窗口增加1，这样就是指数级扩大窗口
    3. 拥塞避免：当增加到某个阈值时，只能按时间间隔，每过一段时间窗口大小+1，线性增长
    4. 这个阈值，如果检测到拥塞发生，就会变为原来的一半
    5. 超时重传：一旦超时，窗口变为1，重新开始慢启动
    6. 快速重传：如果3此收到同一个ack，马上重传包，快速重传要求每个包都要有ack,不要使用捎带应答和延迟应答
    7. 快速恢复：发生快速重传后，阈值马上降低，窗口设为阈值，重新进入拥塞避免阶段
    8. 快速重传+快速恢复就是为了避免进入慢启动阶段。


##### 数据库
1. 为什么使用B+树
  * 答：
    1. **b+树能够有效降低树高度，使得磁盘IO次数最大限度减少**。如果使用AVL树，因为要在内部节点存储数据，所以导致每一页能够存储的节点数是有限的，也就导致磁盘IO次数增加，而AVL树层级又比较高，这个问题会非常严重。
    2. **范围查询->局部性**：b+树的叶子节点是有序的，内部数据也是有序的，这就导致返回查询非常容易，很好的利用了程序局部性原理。
    3. b+树不论节点还是内部每一行数据，在逻辑上是按照顺序存储的，但是在物理上是用双指针模式存储的，这样避免了数组的插入删除，节点分裂等弊端，使得维护成本大大降低
    4. 一个页为16KB，除去必要的节点头部和尾部开销，一个page一般能存储```16KB / (4B + 6B) > 1024```条索引记录，如果一条数据为1KB，那么三层的b+树就可以满足```1024 * 1024 * 16 = 2^24 > 1.6 * 10^7```，也就是千万级别的数据
2. 辅助索引：辅助索引的创建需要尽量保证数据的唯一性。另外，辅助索引导致离散读，innodb一般通过预读(read ahead)来提前加载一些可能会读取的数据到内存，避免离散读导致多次磁盘IO
3. 覆盖索引：覆盖索引指的是查询字段都在辅助索引中，比如```select a, b from table where a = xxx```，如果建立了联合索引```(a,b)```，那么就会直接使用联合索引的结果，因为此时没有必要再取聚簇索引查询了。另一种是统计操作，如果```select count(*) from table where b > xxx and b < yyy```，此时因为联合索引比聚簇索引小的多(聚簇索引的叶子节点是数据，统计时需要读入内存)，索引会用联合索引去做统计，而不走聚簇索引，或者说不走全表扫描。
4. 不使用索引：上面我们说到，辅助索引的找到数据后，再去聚簇索引查数据是离散的，所以如果是```select * from table where b < xxx and b > xxx```，虽然可以通过```b```的索引去找到返回内主键，再通过聚簇索引查到对应的数据，但是此时查询主键是随机的，如果离散读取的数据条数少，那么会走索引，但如果数据条数很多，引擎倾向于直接扫描表，这样是顺序读取，能更好利用机械硬盘的顺序读取特性。但是如果是固态硬盘的话，由于随机读取也很快，所以可以强制指定使用辅助索引
5. binlog
  * 答：
    1. binlog是逻辑日志，记录了每一条变更的sql语句，用于数据库主从同步等复制操作，对于保持```一致性```有一定帮助。另外，在搜索引擎中，如果数据库发生增删改，那么如果此时数据源是mysql数据库，我们的数据源会监听binlog，从而获取到更新信息，向引擎推送一条实时数据，更新实时索引。
6. regolog
  * 答：
    1. redolog是物理日志，记录了xxx页的xxx偏移修改成xxx。redolog用来保证持久性，每一个事务的结束都需要写redolog到磁盘，保证```持久性```，由于redolog是顺序读写，所以性能相比数据的随机读写性能很高
    2. redolog还不能完全保证持久性，因为redolog只是记录了对xxx页的xxx偏移的修改，如果在写一个页的时候，写到一半发生宕机，此时这一页数据就损坏了(磁盘读写一般不能只写一个byte，必须连续写部分区域)，redolog无法恢复，所以在写redolog时，需要备份页，这样当页损坏时，可以先用备份恢复页，然后再利用redolog恢复数据。
    3. 两阶段提交：redolog和binlog很相似，事务提交时，二者的写入顺序如下：
      * 写redolog，redolog在事务开始时就开始了，一条sql就可能有多条redolog，标记为prepare
      * 写binlog，binlog在事务提交时才写入一次，写完binlog后，将redolog标记为commit
      * 如果发生宕机，那么需要处理redolog的prepare状态日志，先去binlog中找，如果binlog写成功了，则提交该事务，如果binlog写失败了，则回滚该事务
7. undolog
  * 答：
    1. undolog记录的是逻辑日志，可以理解为每一条操作的相反操作，比如update，则undolog记录delete，实际是记录了一些信息，用于存储引擎层做数据回滚，而不是真正的sql文本。如果事务失败了，可以用undolog回滚，也就是保证了原子性。**undolog是存储在表空间的，可以当作表来对待，每一条undolog变化都有对应的redolog记录，所以无需担心持久化问题**，同时mvcc也用到了undolog，具体在mvcc目录展开

8. 事务：ACID(Transaction: 交易)
  * 答：
    1. 原子性：要么都成功，要么都失败
    2. 一致性：数据必须始终有效，即满足约束条件。(这里基本都指单机，如果有主从，可能考虑主从一致性问题)
    3. 隔离性：一个事务不能读到其他事务未提交的数据。(read committed就可以满足基本要求)
    4. 持久性：事务一旦提交成功，必须保证永久性，即使宕机，也要能恢复数据
    5. 四种事务隔离级别：读未提交、读已提交、可重复读、串行
    * 读未提交(read uncommitted)：一个事务还没提交时，它做的变更就能被别的事务看到。read uncommited导致**脏读**，这个级别**不满足事务隔离性**
    * 读已提交(read committed): 一个事务提交之后，它做的变更才会被其他事务看到。读已提交会导致**不可重复读->官方叫做幻读**，可以认为不满足**事务一致性**，因为一个事务前后两次读取的数据不一致。但是这一般没有问题
    * 可重复读(read repeatable): 可重复读没有上述问题，但是还存在**并发更新**问题，这个问题本质上是一个并发问题，应用程序中也容易出现，**读->一些操作->写**，两个事务分别执行，就会导致这个问题，只能通过加锁解决。
    * 串行化：没有任何并发问题，加锁
9. **分布式事务**
  * 答：分布式事务的核心是**两阶段提交**
10. 锁
  * 答：
    1. 锁粒度：innodb支持行级锁，分为共享锁和排他锁。而为了更好了控制，innodb还加入了表级意向锁。意向锁之间是互相兼容的，也就是没有竞争关系。意向锁有两个作用：
    * 一是全表扫描时，如果一个查询没有走索引，那么此时就是全表扫描，会使得innodb行锁退化为表锁，此时如果有意向锁，就避免了我们扫描到一半，发现某一行被加锁了，从而导致等待，因为在加行锁之前要先加意向锁。
    2. 超时和死锁：innodb锁超时不会回滚，需要应用程序自己执行rollback。死锁导致的异常除外。
    3. 一致性非锁定读：使用MVCC，即多版本并发控制实现，在读取数据时不加锁
    * MVCC的核心是：每个事务开始时都有一个事务id，每一行数据都有一个最后修改的事务id，undolog的也会在每条记录存储事务id。innodb会维护一个活跃事务和提交事务列表。**创建一个视图，包含所有未提交事务m_ids，已提交事务maxId。要求行rowid <= maxId并且不在m_ids中(视图开始时就已提交)**
    * read committed: select 时创建视图
    * read repeatable: 事务开始时创建视图。read repeatable不阻止数据插入，所以没有完全解决幻读。**RR级别虽然保证了select的一致性，但是没有阻止其他事务插入，如果在事务A中，准备插入一条数据，但在此之前，其他事务已经插入了一条相同的数据，如果有唯一约束，那么此时A的插入就会失败**，此时发生了**类似幻读**
    